from flask import Flask, render_template, request, jsonify
import psycopg2
from psycopg2 import sql
from psycopg2.extras import execute_values, RealDictCursor
import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.sql import text
import os
import matplotlib
matplotlib.use('Agg')  # Utiliser un backend non interactif
import matplotlib.pyplot as plt
from app_config import app
import folium
import geopandas as gpd


# Initialisation de l'application Flask
app = Flask(__name__)

# PostgreSQL Configuration
DATABASE_URL = "postgresql://vogdashboard_user:gXuIhJVeM7XqfsHe77LO0kMbInSLTOIi@dpg-cu9lbptsvqrc73dh3l1g-a.oregon-postgres.render.com/vogdashboard"

DB_CONFIG = {
    "dbname": "vogdashboard",
    "user": "vogdashboard_user",
    "password": "gXuIhJVeM7XqfsHe77LO0kMbInSLTOIi",
    "host": "dpg-cu9lbptsvqrc73dh3l1g-a.oregon-postgres.render.com",
    "port": "5432"
}


from sqlalchemy import create_engine

# Remplacez get_db_connection par l'utilisation d'un moteur SQLAlchemy
def get_db_connection():
    engine = create_engine(f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}")
    return engine

def get_db_connection():
    """Créer une connexion à la base de données PostgreSQL."""
    try:
        conn = psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)
        return conn
    except Exception as e:
        print(f"Erreur de connexion à la base de données : {e}")
        return None

def get_db_connection():
    """Créer une connexion PostgreSQL."""
    try:
        conn = psycopg2.connect(**DB_CONFIG, cursor_factory=RealDictCursor)
        return conn
    except Exception as e:
        print(f"Erreur de connexion à la base de données : {e}")
        return None


        
@app.route("/initialize_db")
def initialize_db():
    create_tables()
    return "Tables créées ou existantes."


@app.route("/test_db")
def test_db():
    engine = get_db_connection()
    if engine:
        try:
            query = "SELECT * FROM ventes LIMIT 5;"
            df = pd.read_sql_query(query, engine)
            return df.to_html()
        except Exception as e: 
            return f"Erreur lors de l'exécution de la requête : {e}"
    else:
        return "Impossible de se connecter à la base de données."

def list_tables():
    engine = get_db_connection()
    if engine:
        try:
            query = "SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';"
            df = pd.read_sql_query(query, engine)
            print("Tables existantes :")
            print(df)
        except Exception as e:
            print(f"Erreur lors de la récupération des tables : {e}")


# on efface les donnees des tables avant ajout des fichiers excel

def truncate_table(table_name, engine):
    """
    Vide une table spécifique dans la base de données en forçant le commit.
    """
    try:
        with engine.connect() as conn:
            conn.execute(text(f'TRUNCATE TABLE "{table_name}" RESTART IDENTITY CASCADE;'))
            conn.commit()  # Force la validation de la transaction
            print(f"La table {table_name} a été vidée avec succès.")
    except Exception as e:
        print(f"Erreur lors du vidage de la table {table_name} : {e}")


# en crée les bases de données
def create_tables():
    conn = get_db_connection()
    if conn:
        try:
            cursor = conn.cursor()
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS Achats (
                    id_achat SERIAL PRIMARY KEY,
                    code_document INTEGER,
                    numero_document TEXT,
                    date_document DATE,
                    fournisseur TEXT,
                    quantite INTEGER,
                    code_article TEXT
                );
                
                CREATE TABLE IF NOT EXISTS LogistiqueProduits (
                    code_article TEXT PRIMARY KEY,
                    poids REAL,
                    nb_par_carton INTEGER,
                    largeur_carton REAL,
                    longueur_carton REAL,
                    hauteur_carton REAL,
                    poids_carton REAL,
                    delai_reapprovisionnement INTEGER
                );
                

            """)
            # Création de la table Stocks
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS Stocks (
                    code_article TEXT PRIMARY KEY,
                    quantite_stock INTEGER NOT NULL DEFAULT 0
                );
            """)
            print("Table 'Stocks' créée ou déjà existante.")


            conn.commit()
        except Exception as e:
            print(f"Erreur lors de la création des tables : {e}")
        finally:
            conn.close()

def create_product_table():
    conn = get_db_connection()
    if conn:
        try:
            cursor = conn.cursor()
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS Produits (
                    code_article TEXT PRIMARY KEY,
                    nom_produit TEXT
                );
            """)
            conn.commit()
        except Exception as e:
            print(f"Erreur lors de la création de la table Produits : {e}")
        finally:
            conn.close()


def import_client_data():
    file_clients = './data/client.xlsx'
    if not os.path.exists(file_clients):
        print("Fichier client.xlsx introuvable dans le dossier ./data. Vérifiez le chemin et réessayez.")
        return

    try:
        # Lecture du fichier Excel
        data_clients = pd.read_excel(file_clients)
        print("Colonnes disponibles dans le fichier clients :")
        print(data_clients.columns)

        # Renommer les colonnes pour correspondre aux noms de la base de données
        data_clients.rename(columns={
            'Code Client': 'code_client',
            'nom': 'nom_client',
            'representant': 'representant',
            'tel': 'tel',
            'email': 'email',
            'DATE CREATION': 'date_creation',
            'ADRESSE': 'adresse',
            'CP': 'cp',
            'VILLE ': 'ville',
            'PAYS': 'pays'
        }, inplace=True)

        # Vérifier les colonnes après renommage
        print("Données prêtes pour insertion :")
        print(data_clients.head())

        # Connexion à PostgreSQL via SQLAlchemy
        engine = create_engine(DATABASE_URL)
        
        # Vider la table avant importation
        truncate_table('client')
        
        if engine:
            # Insérer les données dans la table client
            data_clients.to_sql('client', con=engine, if_exists='append', index=False, method='multi')
            print("Données clients importées avec succès.")
        else:
            print("Erreur : impossible de créer un moteur SQLAlchemy.")
    except Exception as e:
        print(f"Erreur lors de l'importation des données clients : {e}")


# Fonction pour importer les données des stocks
def import_stock_data():
    file_stocks = './data/stock.xlsx'
    if not os.path.exists(file_stocks):
        print("Fichier stock.xlsx introuvable dans le dossier ./data. Vérifiez le chemin et réessayez.")
        return

    try:
        # Charger les données du fichier Excel
        data_stocks = pd.read_excel(file_stocks)
        print("Colonnes disponibles dans le fichier stocks :")
        print(data_stocks.columns)

        # Renommer les colonnes
        data_stocks.rename(columns={
            'Code Article': 'code_article',
            'Stock': 'quantite_stock'
        }, inplace=True)

        # Connexion à la base PostgreSQL via SQLAlchemy
        engine = create_engine(DATABASE_URL)

        # Vider la table stocks avant l'importation
        truncate_table('stocks', engine)

        # Récupérer la liste des `code_article` existants dans la table produits
        query = "SELECT code_article FROM produits;"
        existing_articles = pd.read_sql_query(query, engine)['code_article'].tolist()

        # Filtrer les données pour ne garder que les articles valides
        data_stocks_valid = data_stocks[data_stocks['code_article'].isin(existing_articles)]

        # Vérifier s'il y a des données valides à insérer
        if data_stocks_valid.empty:
            print("Aucune donnée valide à insérer dans la table stocks.")
        else:
            # Insérer uniquement les données valides dans la table stocks
            data_stocks_valid.to_sql('stocks', con=engine, if_exists='append', index=False, method='multi')
            print("Données stocks importées avec succès.")

        # Fermeture de la connexion
        engine.dispose()
    except Exception as e:
        print(f"Erreur lors de l'importation des données stocks : {e}")


# Fonction pour importer les données des produits

def import_product_data():
    file_products = './data/produits.xlsx'
    if not os.path.exists(file_products):
        print("Fichier produits.xlsx introuvable dans le dossier ./data. Vérifiez le chemin et réessayez.")
        return "Fichier produits.xlsx introuvable.", 404

    try:
        # Charger les données du fichier Excel
        data_products = pd.read_excel(file_products)
        print("Colonnes disponibles dans le fichier produits :")
        print(data_products.columns)

        # Renommer les colonnes
        data_products.rename(columns={
            'Code Article': 'code_article',
            'Nom produit': 'nom_produit',
            'Ean': 'ean'
        }, inplace=True)

        # Sélectionner uniquement les colonnes nécessaires
        data_products = data_products[['code_article', 'nom_produit', 'ean']]

        # Convertir 'ean' en chaîne de caractères pour éviter la notation scientifique
        data_products['ean'] = data_products['ean'].apply(lambda x: f"{int(x):013d}" if not pd.isna(x) else None)

        # Afficher un aperçu des données avant l'insertion
        print("Données prêtes pour insertion :")
        print(data_products.head())

        # Connexion directe avec psycopg2 pour exécuter TRUNCATE
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("TRUNCATE TABLE produits RESTART IDENTITY CASCADE;")
        conn.commit()
        cursor.close()
        conn.close()

        # Charger les données dans PostgreSQL via SQLAlchemy
        engine = create_engine(DATABASE_URL)
        data_products.to_sql('produits', con=engine, if_exists='append', index=False, method='multi')

        print("Données produits importées avec succès.")
        return "Données produits importées avec succès.", 200

    except Exception as e:
        print(f"Erreur lors de l'importation des données produits : {e}")
        return f"Erreur lors de l'importation des données produits : {e}", 500
        

# Fonction pour importer les données des ventes
# Fonction pour importer les données des ventes
def import_sales_data():
    file_sales = './data/ventes.xlsx'
    if not os.path.exists(file_sales):
        print("Fichier ventes.xlsx introuvable dans le dossier ./data. Vérifiez le chemin et réessayez.")
        return

    try:
        # Charger le fichier Excel
        data_sales = pd.read_excel(file_sales)
        print("Colonnes disponibles dans le fichier ventes :")
        print(data_sales.columns)

        # Renommer les colonnes pour correspondre à la base de données
        data_sales.rename(columns={
            'Date': 'date_vente',
            'Num pièce': 'num_piece',
            'Code client': 'code_client',
            'Code Article': 'code_article',
            'Quantite': 'quantite_vendue',
            'Prix achat': 'prix_achat'
        }, inplace=True)

        # Conserver uniquement les colonnes nécessaires
        expected_columns = ['date_vente', 'num_piece', 'code_client', 'code_article', 'quantite_vendue', 'prix_achat']
        if not all(col in data_sales.columns for col in expected_columns):
            missing_columns = [col for col in expected_columns if col not in data_sales.columns]
            print(f"Colonnes manquantes dans le fichier Excel : {missing_columns}")
            return

        data_sales = data_sales[expected_columns]

        # Conversion des dates
        data_sales['date_vente'] = pd.to_datetime(data_sales['date_vente'], errors='coerce')

        # Supprimer les lignes avec des dates invalides ou des valeurs manquantes dans les colonnes clés
        data_sales = data_sales.dropna(subset=['date_vente', 'code_client', 'code_article', 'quantite_vendue', 'prix_achat'])

        # Remplacer les valeurs non valides par des zéros
        data_sales['quantite_vendue'] = pd.to_numeric(data_sales['quantite_vendue'], errors='coerce').fillna(0).astype(int)
        data_sales['prix_achat'] = pd.to_numeric(data_sales['prix_achat'], errors='coerce').fillna(0.0).astype(float)

        # Connexion à la base PostgreSQL via SQLAlchemy
        engine = create_engine(DATABASE_URL)

        # Vider la table avant importation
        try:
            truncate_table('Ventes', engine)
        except Exception as e:
            print(f"Erreur lors du vidage de la table Ventes : {e}")
            return

        # Vérifier si la table est bien vidée
        with engine.connect() as conn:
            result = conn.execute(text('SELECT COUNT(*) FROM "Ventes";'))
            count = result.scalar()
            print(f"Nombre de lignes dans la table Ventes après vidage : {count}")
            if count != 0:
                print("La table Ventes n'a pas été vidée correctement. Vérifiez la commande TRUNCATE.")
                return

        # Vérifier que les clients existent dans la table client
        query = "SELECT code_client FROM client"
        existing_clients = pd.read_sql_query(query, engine)['code_client'].tolist()

        # Filtrer les ventes pour ne conserver que celles avec des clients existants
        data_sales = data_sales[data_sales['code_client'].isin(existing_clients)]
        if data_sales.empty:
            print("Aucune donnée valide à insérer dans la table Ventes.")
            return

        # Afficher un aperçu des données prêtes pour insertion
        print("Données prêtes pour insertion :")
        print(data_sales.head())

        # Insérer les données dans PostgreSQL
        with engine.begin() as conn:
            data_sales.to_sql('Ventes', con=conn, if_exists='append', index=False, method='multi')

        # Vérification post-insertion
        with engine.connect() as conn:
            result = conn.execute(text('SELECT COUNT(*) FROM "Ventes";'))
            count_after = result.scalar()
            print(f"Nombre de lignes dans la table Ventes après insertion : {count_after}")

        print("Données ventes importées avec succès.")

    except Exception as e:
        print(f"Erreur lors de l'importation des données ventes : {e}")





# Fonction pour importer les données des achats
def import_purchase_data():

    file_purchases = './data/achats.xlsx'
    if not os.path.exists(file_purchases):
        print("Fichier achats.xlsx introuvable dans le dossier ./data. Vérifiez le chemin et réessayez.")
        return

    try:
        # Charger le fichier Excel
        data_purchases = pd.read_excel(file_purchases)
        print("Colonnes disponibles dans le fichier achats :")
        print(data_purchases.columns)

        # Renommer les colonnes pour correspondre à la base de données
        data_purchases.rename(columns={
            'code_document': 'code_document',
            'numero_document': 'numero_document',
            'date_document': 'date_document',
            'fournisseur': 'fournisseur',
            'quantite': 'quantite',
            'code_article': 'code_article'
        }, inplace=True)

        # Conserver uniquement les colonnes nécessaires
        expected_columns = ['code_document', 'numero_document', 'date_document', 'fournisseur', 'quantite', 'code_article']
        data_purchases = data_purchases[expected_columns]

        # Conversion des dates au format JJMMAA
        def convert_date(date_str):
            try:
                return pd.to_datetime(date_str, format='%d%m%y').strftime('%Y-%m-%d')
            except ValueError:
                return None

        data_purchases['date_document'] = data_purchases['date_document'].astype(str).apply(convert_date)

        # Supprimer les lignes avec des dates invalides ou des valeurs manquantes
        data_purchases = data_purchases.dropna(subset=['date_document', 'code_article'])

        # Récupérer les articles existants dans la table produits
        engine = create_engine(DATABASE_URL)
        query = "SELECT code_article FROM produits"
        existing_articles = pd.read_sql_query(query, engine)['code_article'].tolist()

        # Filtrer les achats pour ne conserver que ceux avec des articles existants
        data_purchases = data_purchases[data_purchases['code_article'].isin(existing_articles)]
        if data_purchases.empty:
            print("Aucune donnée valide à insérer dans la table achats.")
            return

        # Afficher un aperçu des données prêtes pour insertion
        print("Données prêtes pour insertion :")
        print(data_purchases.head())

        # Insérer les données dans PostgreSQL
        data_purchases.to_sql('achats', con=engine, if_exists='append', index=False, method='multi')
        print("Données achats importées avec succès.")
    except Exception as e:
        print(f"Erreur lors de l'importation des données achats : {e}")



@app.route("/sales_palmares")
def sales_palmares():
    # Utilisez un moteur SQLAlchemy pour la connexion
    engine = create_engine(DATABASE_URL)
    try:
        # Requête pour obtenir le palmarès des ventes
        query = '''
        SELECT 
            p.code_article AS code_article,
            p.nom_produit,
            COALESCE(s.quantite_stock, 0) AS quantite_stock,
            SUM(CASE WHEN EXTRACT(YEAR FROM v.date_vente) = 2023 THEN v.quantite_vendue ELSE 0 END) AS vente_2023,
            SUM(CASE WHEN EXTRACT(YEAR FROM v.date_vente) = 2024 THEN v.quantite_vendue ELSE 0 END) AS vente_2024,
            SUM(CASE WHEN EXTRACT(YEAR FROM v.date_vente) = 2025 THEN v.quantite_vendue ELSE 0 END) AS vente_2025
        FROM 
            produits p
        LEFT JOIN 
            stocks s ON p.code_article = s.code_article
        LEFT JOIN 
            "Ventes" v ON p.code_article = v.code_article
        GROUP BY 
            p.code_article, p.nom_produit, s.quantite_stock
        ORDER BY 
            vente_2024 DESC;
        '''
        # Utilisez pandas pour exécuter la requête
        df = pd.read_sql_query(query, engine)

        # Vérifiez s'il y a des données
        if df.empty:
            return "<h1>Aucune donnée disponible pour le palmarès des ventes.</h1>"

        # Convertir les données en HTML pour affichage
        return render_template("sales_palmares.html", sales=df.to_dict(orient="records"))

    except Exception as e:
        return f"Erreur lors de l'exécution de la requête : {e}"

    finally:
        # Fermez le moteur SQLAlchemy correctement
        engine.dispose()
        
#fonction pour la recherche
@app.route('/search')
def search():
    # Utilisez un moteur SQLAlchemy pour la connexion
    engine = create_engine(DATABASE_URL)
    query = request.args.get('q', '').strip().lower()  # Nettoyer et convertir la requête en minuscule
    if not query:
        return jsonify([])  # Retourne une liste vide si aucun mot-clé n'est fourni

    try:
        # Connexion à la base de données
        with engine.connect() as conn:
            search_query = text("""
                SELECT code_article, nom_produit
                FROM produits
                WHERE LOWER(code_article) LIKE :query OR LOWER(nom_produit) LIKE :query
                LIMIT 10
            """)
            results = conn.execute(search_query, {"query": f"%{query}%"}).fetchall()

            print(f"Requête reçue pour : {query}")  # Log pour debug

            # Retourner les résultats sous forme de JSON
            return jsonify([
                {"code_article": row[0], "nom_produit": row[1]}
                for row in results
            ])
    except Exception as e:
        print(f"Erreur lors de l'exécution de la requête de recherche : {e}")
        return jsonify({"error": "Une erreur s'est produite lors de la recherche"}), 500
        
@app.route('/all_representative_sales')
def dynamic_representative_sales():
    # Créer un moteur SQLAlchemy pour la connexion
    engine = create_engine(DATABASE_URL)  # Remplacez par votre `DATABASE_URL`
    try:
        # Requête SQL pour obtenir les ventes mensuelles par représentant
        query = '''
        SELECT
            c.representant AS nom_representant,
            TO_CHAR(v.date_vente, 'YYYY-MM') AS mois,
            SUM(v.quantite_vendue * v.prix_achat) AS chiffre_affaire
        FROM
            "Ventes" v
        JOIN
            client c ON v.code_client = c.code_client
        GROUP BY
            c.representant, TO_CHAR(v.date_vente, 'YYYY-MM')
        ORDER BY
            c.representant, mois;
        '''
        # Utilisation de `read_sql_query` avec le moteur SQLAlchemy
        sales_data = pd.read_sql_query(query, con=engine)

        # Vérifier si les données sont vides
        if sales_data.empty:
            return "<h1>Aucune donnée disponible pour les représentants.</h1>"

        # Transformation en tableau pivot pour créer des colonnes mois par mois
        sales_pivot = sales_data.pivot_table(
            index='nom_representant',
            columns='mois',
            values='chiffre_affaire',
            fill_value=0
        ).reset_index()

        # Calcul du chiffre d'affaires moyen pour chaque mois
        average_sales = sales_pivot.drop(columns=['nom_representant']).mean().to_dict()

        # Préparation des données pour le modèle
        representative_sales = sales_pivot.to_dict(orient='records')

        return render_template(
            'all_representative_sales.html',
            representative_sales=representative_sales,
            average_sales=average_sales
        )

    except Exception as e:
        return f"Erreur lors de l'exécution de la requête : {e}"

    finally:
        # Libération du moteur SQLAlchemy
        engine.dispose()


# Fonction pour obtenir les ventes mensuelles par représentant et le CA moyen
def get_monthly_sales_and_average():
    engine = get_db_connection()

    try:
        # Étape 1 : Requête SQL pour obtenir les ventes mensuelles par représentant
        query = '''
        SELECT
            c.representant AS nom_representant,
            TO_CHAR(v.date_vente, 'YYYY-MM') AS mois,
            SUM(v.quantite_vendue * v.prix_achat) AS chiffre_affaire
        FROM
            "Ventes" v
        JOIN
            client c ON v.code_client = c.code_client
        GROUP BY
            c.representant, TO_CHAR(v.date_vente, 'YYYY-MM')
        ORDER BY
            c.representant, mois;
        '''
        sales_data = pd.read_sql_query(query, engine)

        # Vérifier s'il y a des données
        if sales_data.empty:
            return None, None

        # Étape 2 : Calcul du chiffre d'affaires moyen par mois
        average_sales = (
            sales_data.groupby('mois')['chiffre_affaire']
            .sum()  # Total du CA par mois
            / sales_data.groupby('mois')['nom_representant'].nunique()  # Nombre unique de représentants actifs
        ).reset_index()

        average_sales.columns = ['mois', 'ca_moyen']

        print("Données de vente mensuelles par représentant :")
        print(sales_data)

        print("Chiffre d'affaires moyen par mois :")
        print(average_sales)

        return sales_data, average_sales

    except Exception as e:
        print(f"Erreur lors de l'exécution de la requête : {e}")
        return None, None

    finally:
        engine.dispose()


# Route pour afficher les ventes mensuelles par pharmacie pour un produit
@app.route('/product/<code_article>/monthly_sales')
def monthly_sales(code_article):
    # Obtenir les ventes mensuelles par pharmacie
    monthly_sales_data = get_monthly_sales_by_pharmacy(code_article)

    # Si aucune donnée n'est retournée, afficher un message approprié
    if monthly_sales_data is None or monthly_sales_data.empty:
        return f"<h1>Aucune donnée de vente disponible pour le produit : {code_article}</h1>"

    # Rendu de la page HTML avec les données
    return render_template(
        'monthly_sales.html',
        tables=monthly_sales_data.to_dict(orient='records'),
        code_article=code_article
    )


# Fonction pour obtenir les ventes mensuelles par pharmacie pour un produit spécifique
def get_monthly_sales_by_pharmacy(code_article):
    engine = create_engine(DATABASE_URL)  # Créez un moteur SQLAlchemy
    query = '''
    SELECT
        c.code_client AS code_client,
        c.nom_client AS nom_pharmacie,
        c.representant AS nom_representant,
        TO_CHAR(v.date_vente, 'YYYY-MM') AS mois,
        SUM(v.quantite_vendue * v.prix_achat) AS chiffre_affaire
    FROM
        "Ventes" v
    JOIN
        Client c ON v.code_client = c.code_client
    WHERE
        v.code_article = %(code_article)s
    GROUP BY
        c.code_client, c.nom_client, c.representant, TO_CHAR(v.date_vente, 'YYYY-MM')
    ORDER BY
        c.nom_client, mois;
    '''
    try:
        # Exécutez la requête avec SQLAlchemy
        sales_data = pd.read_sql_query(query, con=engine, params={'code_article': code_article})

        # Transformation en table pivot
        if not sales_data.empty:
            sales_pivot = sales_data.pivot_table(
                index=['code_client', 'nom_pharmacie', 'nom_representant'],
                columns='mois',
                values='chiffre_affaire',
                fill_value=0
            ).reset_index()
        else:
            sales_pivot = pd.DataFrame(columns=['code_client', 'nom_pharmacie', 'nom_representant'])

        print(f"Ventes mensuelles par pharmacie pour le produit {code_article} :")
        print(sales_pivot)
        return sales_pivot
    except Exception as e:
        print(f"Erreur lors de la récupération des ventes mensuelles par pharmacie : {e}")
        return None
    finally:
        engine.dispose()  # Disposez du moteur SQLAlchemy pour libérer les ressources


# Route pour afficher les ventes, produits reçus et produits commandés mensuels par produit
@app.route('/product/<code_article>/monthly_sales_product')
def monthly_sales_product(code_article):
    monthly_data = get_monthly_sales_and_purchases(code_article)
    if monthly_data is None or monthly_data.empty:
        return f"<h1>Aucune donnée disponible pour le produit : {code_article}</h1>"
    return render_template('monthly_sales_product.html', tables=monthly_data.to_dict(orient='records'), code_article=code_article)


# Fonction pour obtenir les ventes, achats et commandes mensuels pour un produit spécifique
def get_monthly_sales_and_purchases(code_article):
    engine = create_engine(DATABASE_URL)  # Créez un moteur SQLAlchemy

    try:
        # Requête pour les ventes
        sales_query = '''
        SELECT
            TO_CHAR(date_vente, 'YYYY-MM') AS mois,
            SUM(quantite_vendue) AS quantite_vendue
        FROM
            "Ventes"
        WHERE
            code_article = %s
        GROUP BY
            mois
        ORDER BY
            mois;
        '''
        sales_data = pd.read_sql_query(sales_query, engine, params=(code_article,))  # Passez un tuple

        # Requête pour les produits reçus
        received_query = '''
        SELECT
            TO_CHAR(date_document, 'YYYY-MM') AS mois,
            SUM(quantite) AS quantite_achetee
        FROM
            "achats"
        WHERE
            code_article = %s AND code_document = 16
        GROUP BY
            mois
        ORDER BY
            mois;
        '''
        received_data = pd.read_sql_query(received_query, engine, params=(code_article,))  # Passez un tuple

        # Requête pour les produits commandés
        ordered_query = '''
        SELECT
            TO_CHAR(date_document, 'YYYY-MM') AS mois,
            SUM(quantite) AS quantite_commandee
        FROM
            "achats"
        WHERE
            code_article = %s AND code_document = 12
        GROUP BY
            mois
        ORDER BY
            mois;
        '''
        ordered_data = pd.read_sql_query(ordered_query, engine, params=(code_article,))  # Passez un tuple

        # Fusionner les données
        combined_data = pd.merge(sales_data, received_data, on='mois', how='outer', suffixes=('_v', '_r')).fillna(0)
        combined_data = pd.merge(combined_data, ordered_data, on='mois', how='outer', suffixes=('', '_o')).fillna(0)

        # Convertir les colonnes en types numériques
        combined_data['quantite_vendue'] = pd.to_numeric(combined_data['quantite_vendue'], errors='coerce').fillna(0).astype(int)
        combined_data['quantite_achetee'] = pd.to_numeric(combined_data['quantite_achetee'], errors='coerce').fillna(0).astype(int)
        combined_data['quantite_commandee'] = pd.to_numeric(combined_data['quantite_commandee'], errors='coerce').fillna(0).astype(int)

        print(f"Données combinées pour le produit {code_article} :")
        print(combined_data)

        return combined_data
    except Exception as e:
        print(f"Erreur lors de la récupération des données pour le produit {code_article} : {e}")
        return None
    finally:
        engine.dispose()  # Ferme le moteur proprement



# Route pour afficher les ventes par représentant PAR PRODUIT
@app.route('/product/<code_article>')
def product_sales(code_article):
    try:
        sales_data = get_sales_by_representative(code_article)
        if sales_data.empty:
            return f"<h1>Aucune donnée de vente trouvée pour le produit {code_article}.</h1>"

        return render_template(
            'product_sales.html',
            tables=sales_data.to_dict(orient='records'),
            code_article=code_article
        )
    except Exception as e:
        return f"Erreur lors de la récupération des ventes pour le produit {code_article} : {e}"

# Fonction pour obtenir les ventes par représentant pour un produit spécifique
def get_sales_by_representative(code_article):
    engine = create_engine(DATABASE_URL)  # Utilise SQLAlchemy pour la connexion

    query = '''
    SELECT
        COALESCE(c.representant, 'Inconnu') AS nom_representant,
        p.nom_produit,
        SUM(CASE WHEN EXTRACT(YEAR FROM v.date_vente) = 2023 THEN v.quantite_vendue ELSE 0 END) AS vente_2023,
        SUM(CASE WHEN EXTRACT(YEAR FROM v.date_vente) = 2024 THEN v.quantite_vendue ELSE 0 END) AS vente_2024,
        SUM(CASE WHEN EXTRACT(YEAR FROM v.date_vente) = 2025 THEN v.quantite_vendue ELSE 0 END) AS vente_2025
    FROM
        "Ventes" v
    LEFT JOIN
        "produits" p ON v.code_article = p.code_article
    LEFT JOIN
        "client" c ON v.code_client = c.code_client
    WHERE
        v.code_article = %s
    GROUP BY
        c.representant, p.nom_produit
    ORDER BY
        vente_2024 DESC, vente_2023 DESC, vente_2025 DESC;
    '''
    try:
        result = pd.read_sql_query(query, engine, params=(code_article,))
        print(f"Données récupérées pour le produit {code_article} :")
        print(result)
        return result
    except Exception as e:
        print(f"Erreur lors de la récupération des ventes pour le produit {code_article} : {e}")
        raise
    finally:
        engine.dispose()  # Ferme proprement le moteur SQLAlchemy


# Route pour afficher le formulaire d'ajout ou de modification des détails d'un produit
@app.route('/add_product_form')
def add_product_form():
    engine = create_engine(DATABASE_URL)  # Utilise SQLAlchemy pour la connexion
    code_article = request.args.get('code_article', '')
    existing_data = None

    if code_article:
        with engine.connect() as conn:
            query = """
                SELECT code_article, poids, nb_par_carton, largeur_carton, longueur_carton, hauteur_carton, 
                       poids_carton, delai_reapprovisionnement
                FROM logistiqueproduits
                WHERE code_article = :code_article;
            """
            result = conn.execute(text(query), {"code_article": code_article}).fetchone()

            if result:
                # Convertir le résultat en dictionnaire pour faciliter l'accès dans le template
                existing_data = dict(result)

    return render_template('add_product_form.html', code_article=code_article, existing_data=existing_data)

# Route pour traiter le formulaire et insérer ou mettre à jour les données
@app.route('/add_product_details', methods=['POST'])
def add_product_details():
    engine = create_engine(DATABASE_URL)  # Utilise SQLAlchemy pour la connexion
    # Récupérer les données du formulaire
    code_article = request.form['code_article']
    poids = request.form['poids']
    nb_par_carton = request.form['nb_par_carton']
    largeur_carton = request.form['largeur_carton']
    longueur_carton = request.form['longueur_carton']
    hauteur_carton = request.form['hauteur_carton']
    poids_carton = request.form['poids_carton']
    delai_reapprovisionnement = request.form['delai_reapprovisionnement']

    try:
        with engine.connect() as conn:
            transaction = conn.begin()  # Démarre une transaction

            try:
                # Vérifier si des données logistiques existent déjà pour ce produit
                check_query = "SELECT 1 FROM logistiqueproduits WHERE code_article = :code_article;"
                existing_entry = conn.execute(text(check_query), {"code_article": code_article}).fetchone()

                if existing_entry:
                    # Si les données existent, les mettre à jour
                    update_query = """
                        UPDATE logistiqueproduits
                        SET poids = :poids, nb_par_carton = :nb_par_carton, largeur_carton = :largeur_carton, 
                            longueur_carton = :longueur_carton, hauteur_carton = :hauteur_carton, 
                            poids_carton = :poids_carton, delai_reapprovisionnement = :delai_reapprovisionnement
                        WHERE code_article = :code_article;
                    """
                    conn.execute(text(update_query), {
                        "poids": poids,
                        "nb_par_carton": nb_par_carton,
                        "largeur_carton": largeur_carton,
                        "longueur_carton": longueur_carton,
                        "hauteur_carton": hauteur_carton,
                        "poids_carton": poids_carton,
                        "delai_reapprovisionnement": delai_reapprovisionnement,
                        "code_article": code_article
                    })
                    message = f"Les détails du produit {code_article} ont été mis à jour avec succès."
                else:
                    # Sinon, insérer une nouvelle entrée
                    insert_query = """
                        INSERT INTO logistiqueproduits 
                        (code_article, poids, nb_par_carton, largeur_carton, longueur_carton, hauteur_carton, 
                         poids_carton, delai_reapprovisionnement)
                        VALUES (:code_article, :poids, :nb_par_carton, :largeur_carton, :longueur_carton, 
                                :hauteur_carton, :poids_carton, :delai_reapprovisionnement);
                    """
                    conn.execute(text(insert_query), {
                        "code_article": code_article,
                        "poids": poids,
                        "nb_par_carton": nb_par_carton,
                        "largeur_carton": largeur_carton,
                        "longueur_carton": longueur_carton,
                        "hauteur_carton": hauteur_carton,
                        "poids_carton": poids_carton,
                        "delai_reapprovisionnement": delai_reapprovisionnement
                    })
                    message = f"Les détails du produit {code_article} ont été ajoutés avec succès."

                transaction.commit()  # Valider la transaction

            except Exception as e:
                transaction.rollback()  # Annuler la transaction en cas d'erreur
                return f"Erreur lors de l'ajout ou de la mise à jour des détails du produit : {e}"

        return message

    except Exception as e:
        return f"Erreur lors de la connexion ou de l'exécution de la requête : {e}"
        

@app.route('/afficheproduit/<code_article>')
def product_details_route(code_article):
    engine = create_engine(DATABASE_URL)  # Utilise SQLAlchemy pour la connexion
    try:
        with engine.connect() as conn:
            # Récupérer les détails du produit
            query_product_details = text("""
                SELECT 
                    p.code_article, p.nom_produit, 
                    lp.poids, lp.nb_par_carton, lp.largeur_carton, 
                    lp.longueur_carton, lp.hauteur_carton, lp.poids_carton,
                    lp.delai_reapprovisionnement
                FROM produits p
                    LEFT JOIN logistiqueproduits lp ON p.code_article = lp.code_article
                WHERE p.code_article = :code_article
            """)
            product_details = conn.execute(query_product_details, {"code_article": code_article}).fetchone()

            if not product_details:
                return f"Produit avec le code {code_article} introuvable.", 404

            # Calculer le stock moyen
            query_received = text("""
                SELECT SUM(quantite) AS total_recu
                FROM achats
                WHERE code_article = :code_article
            """)
            total_recu = conn.execute(query_received, {"code_article": code_article}).scalar() or 0

            query_sold = text("""
                SELECT SUM(quantite_vendue) AS total_vendu
                FROM "Ventes"
                WHERE code_article = :code_article
            """)
            total_vendu = conn.execute(query_sold, {"code_article": code_article}).scalar() or 0

            stock_moyen = total_recu - total_vendu

            # Calculer la quantité moyenne mensuelle vendue sur les 12 derniers mois
            query_avg_monthly_sales = text("""
                SELECT AVG(monthly_sales.total) AS avg_monthly_sales
                FROM (
                SELECT SUM(v.quantite_vendue) AS total
                FROM "Ventes" v
                WHERE v.code_article = :code_article 
                AND v.date_vente >= CURRENT_DATE - INTERVAL '12 months'
                GROUP BY DATE_TRUNC('month', v.date_vente)
                ) AS monthly_sales
            """)
            avg_monthly_sales = conn.execute(query_avg_monthly_sales, {"code_article": code_article}).scalar() or 0

            avg_daily_sales = avg_monthly_sales / 30 if avg_monthly_sales else 0
            delai_reapprovisionnement = product_details[8] or 0
            stock_securite_total = round(avg_daily_sales * delai_reapprovisionnement + avg_monthly_sales, 2)

            # Récupérer le stock actuel
            query_current_stock = text("""
                SELECT quantite_stock
                FROM stocks
                WHERE code_article = :code_article
            """)
            current_stock = conn.execute(query_current_stock, {"code_article": code_article}).scalar() or 0

            # Récupérer les données mensuelles des ventes
            query_monthly_data = text("""
                SELECT TO_CHAR(date_vente, 'YYYY-MM') AS mois,
                       SUM(quantite_vendue) AS total_vendu
                FROM "Ventes"
                WHERE code_article = :code_article
                GROUP BY TO_CHAR(date_vente, 'YYYY-MM')
                ORDER BY mois ASC
            """)
            ventes_mensuelles = conn.execute(query_monthly_data, {"code_article": code_article}).fetchall()

            # Récupérer les données mensuelles des achats
            query_stock_monthly_data = text("""
                SELECT TO_CHAR(date_document, 'YYYY-MM') AS mois,
                       SUM(quantite) AS total_stock
                FROM achats
                WHERE code_article = :code_article AND code_document = 16
                GROUP BY TO_CHAR(date_document, 'YYYY-MM')
                ORDER BY mois ASC 
            """)
            stocks_mensuels = conn.execute(query_stock_monthly_data, {"code_article": code_article}).fetchall()

            # Structurer les données pour le graphique en filtrant les dates invalides
            mois_labels = sorted({row[0] for row in ventes_mensuelles if row[0]} | {row[0] for row in stocks_mensuels if row[0]})
            ventes_dict = {row[0]: row[1] for row in ventes_mensuelles if row[0]}
            stocks_dict = {row[0]: row[1] for row in stocks_mensuels if row[0]}
            data_ventes = [ventes_dict.get(mois, 0) for mois in mois_labels]
            data_stocks = [stocks_dict.get(mois, 0) for mois in mois_labels]

            # Rendre la page HTML
            return render_template('product_details.html',
                                   product={
                                       'code_article': product_details[0],
                                       'nom_produit': product_details[1],
                                       'poids': product_details[2],
                                       'nb_par_carton': product_details[3],
                                       'largeur_carton': product_details[4],
                                       'longueur_carton': product_details[5],
                                       'hauteur_carton': product_details[6],
                                       'poids_carton': product_details[7],
                                       'delai_reapprovisionnement': delai_reapprovisionnement,
                                       'stock_moyen': stock_moyen,
                                       'avg_monthly_sales': round(avg_monthly_sales, 2),
                                       'avg_daily_sales': round(avg_daily_sales, 2),
                                       'stock_securite_total': stock_securite_total,
                                       'current_stock': current_stock
                                   },
                                   chart_data={
                                       'labels': mois_labels,
                                       'ventes': data_ventes,
                                       'stocks': data_stocks
                                   })
    except Exception as e:
        print(f"Erreur lors de la récupération des détails du produit : {e}")
        return f"Erreur lors de la récupération des détails du produit : {e}", 500  



@app.route('/')
def dashboard():
    engine = create_engine(DATABASE_URL)  # Utilise SQLAlchemy pour la connexion
    try:
        with engine.connect() as conn:
            # 1. Chiffre d'affaires global du mois
            ca_mois = conn.execute(text("""
                SELECT 
                    COALESCE(SUM(quantite_vendue * prix_achat), 0) AS ca_mois
                FROM "Ventes"
                WHERE DATE_TRUNC('month', date_vente) = DATE_TRUNC('month', CURRENT_DATE);
            """)).scalar() or 0

            # 2. Évolution du chiffre d'affaires
            evolution_data = conn.execute(text("""
                WITH ca_courant AS (
                    SELECT 
                        COALESCE(SUM(quantite_vendue * prix_achat), 0) AS ca_mois_courant
                    FROM "Ventes"
                    WHERE DATE_TRUNC('month', date_vente) = DATE_TRUNC('month', CURRENT_DATE)
                ),
                ca_annee_precedente AS (
                    SELECT 
                        COALESCE(SUM(quantite_vendue * prix_achat), 0) AS ca_mois_precedent
                    FROM "Ventes"
                    WHERE DATE_TRUNC('month', date_vente) = DATE_TRUNC('month', CURRENT_DATE) - INTERVAL '1 year'
                )
                SELECT 
                    CAST(ROUND(ca_courant.ca_mois_courant) AS INTEGER) AS ca_mois_courant,
                    CAST(ROUND(ca_annee_precedente.ca_mois_precedent) AS INTEGER) AS ca_mois_precedent,
                    CAST(ROUND(
                        ((ca_courant.ca_mois_courant - ca_annee_precedente.ca_mois_precedent) 
                        / NULLIF(ca_annee_precedente.ca_mois_precedent, 0)) * 100
                    ) AS INTEGER) AS evolution
                FROM ca_courant, ca_annee_precedente;
            """)).fetchone()

            ca_mois_courant = evolution_data[0] or 0
            ca_mois_precedent = evolution_data[1] or 0
            evolution = evolution_data[2] or 0

            # 3. Top 10 des produits les plus vendus
            top_products = conn.execute(text("""
                SELECT 
                    v.code_article,
                    p.nom_produit,
                    SUM(v.quantite_vendue) AS quantite_totale,
                    CAST(SUM(v.quantite_vendue * v.prix_achat) AS INTEGER) AS chiffre_affaire
                FROM "Ventes" v
                JOIN produits p ON v.code_article = p.code_article
                WHERE DATE_TRUNC('month', v.date_vente) = DATE_TRUNC('month', CURRENT_DATE)
                GROUP BY v.code_article, p.nom_produit
                ORDER BY quantite_totale DESC
                LIMIT 10;
            """)).fetchall()

            # 4. Top 5 des représentants ayant fait le plus de chiffre
            top_representatives = conn.execute(text("""
                SELECT 
                    c.representant AS nom_representant,
                    CAST(SUM(v.quantite_vendue * v.prix_achat) AS INTEGER) AS chiffre_affaire
                FROM "Ventes" v
                JOIN client c ON v.code_client = c.code_client
                WHERE DATE_TRUNC('month', v.date_vente) = DATE_TRUNC('month', CURRENT_DATE)
                GROUP BY c.representant
                ORDER BY chiffre_affaire DESC
                LIMIT 5;
            """)).fetchall()

        # Retourne les données pour affichage
        return render_template(
            'dashboard.html', 
            ca_mois=ca_mois_courant,
            evolution=evolution,
            top_products=top_products,
            top_representatives=top_representatives
        )
    except Exception as e:
        return f"Erreur lors du chargement du tableau de bord : {e}", 500
        



# Chargement de la correspondance code département -> nom département
department_mapping = pd.read_csv("./data/departements.csv")  # Fichier contenant les colonnes "code" et "nom"

@app.route('/carte_ventes_agents')
def carte_ventes_agents():
    engine = create_engine(DATABASE_URL)  # Utilise SQLAlchemy pour la connexion
    try:
        # Étape 1 : Récupérer les données des ventes et agents par département
        query = text("""
            SELECT
                LEFT(c.cp::TEXT, 2) AS code_departement,
                COUNT(DISTINCT c.code_client) AS nb_clients,
                STRING_AGG(DISTINCT c.representant, ', ') AS nom_agents
            FROM client c
            JOIN "Ventes" v ON c.code_client = v.code_client
            GROUP BY LEFT(c.cp::TEXT, 2)
        """)
        data = pd.read_sql_query(query, engine)

        # Vérifier que des données ont été récupérées
        if data.empty:
            return "<h1>Aucune donnée disponible pour la carte des ventes.</h1>"

        # Étape 2 : Charger les données géographiques des départements
        france_departments = gpd.read_file("https://france-geojson.gregoiredavid.fr/repo/departements.geojson")

        # Étape 3 : Fusionner les données des départements avec les données clients et agents
        data.rename(columns={"code_departement": "code"}, inplace=True)  # Adapter les noms pour la fusion
        map_data = france_departments.merge(data, on="code", how="left")

        # Étape 4 : Créer une carte interactive avec Folium
        m = folium.Map(location=[46.603354, 1.888334], zoom_start=6)

        # Ajouter un choropleth pour le nombre de clients par département
        folium.Choropleth(
            geo_data=map_data,
            name="choropleth",
            data=map_data,
            columns=["code", "nb_clients"],
            key_on="feature.properties.code",
            fill_color="YlGn",
            fill_opacity=0.7,
            line_opacity=0.2,
            legend_name="Nombre de clients par département"
        ).add_to(m)

        # Ajouter des popups avec des informations supplémentaires pour chaque département
        for _, row in map_data.iterrows():
            if pd.notna(row["geometry"]):
                popup_content = f"""
                <b>Département :</b> {row['nom']}<br>
                <b>Agents :</b> {row['nom_agents'] or 'Aucun'}<br>
                <b>Clients :</b> {row['nb_clients'] or 0}
                """
                folium.Popup(popup_content, max_width=300).add_to(
                    folium.GeoJson(row["geometry"])
                )

        # Étape 5 : Sauvegarder la carte dans un fichier HTML
        m.save("templates/carte_ventes_agents.html")

        return render_template("carte_ventes_agents.html")

    except Exception as e:
        return f"Erreur lors de la génération de la carte : {e}", 500





        


@app.route("/import_clients")
def import_clients():
    import_client_data()
    return "Importation des données clients terminée."

@app.route("/import_stocks")
def import_stocks():
    import_stock_data()
    return "Importation des données stocks terminée."

@app.route("/import_products")
def import_products():
    import_product_data()
    return "Importation des données produits terminée."

@app.route("/import_sales")
def import_sales():
    import_sales_data()
    return "Importation des données ventes terminée."

@app.route("/import_purchases")
def import_purchases():
    import_purchase_data()
    return "Importation des données achats terminée."

    
# Route principale pour afficher le palmarès
@app.route('/')
def palmares():
    order_by = request.args.get('order_by', 'vente_2024 DESC')
    palmares_data = get_palmares(order_by)
    return render_template('palmares.html', tables=palmares_data.to_dict(orient='records'), order_by=order_by)    

    
@app.route('/test/<name>')
def test_dynamic_route(name):
    return f"Bonjour, {name} !"  
    
    

if __name__ == '__main__':
    create_tables()
    create_product_table()
    app.run(debug=True)
    app.config['DEBUG'] = True

